This project is a Retrieval-Augmented Generation (RAG) system built to demonstrate the working and architecture of document-grounded AI applications. The system processes PDF documents, converts their content into embeddings, and stores them in a vector database. When a user asks a question, only the most relevant content is retrieved and used to generate responses via a local LLM, ensuring answers are strictly based on the provided documents rather than general model knowledge.

The system has been enhanced to support multiple PDFs, allowing queries across all uploaded documents. A Streamlit-based chat interface is integrated to improve accessibility, usability, and clarity, making it easier for users to interact with the system and understand where answers are derived from.

This project is intended for learning and demonstration purposes and serves as a foundation for building more advanced RAG-based applications.
